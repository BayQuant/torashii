{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"math/","title":"Torashii Math","text":"<p>Basic mathematical and statistical operations used in the model.</p>"},{"location":"math/#torashii.math.center_xsection","title":"<code>center_xsection(target_col, over_col, standardize=False)</code>","text":"<p>Cross-sectionally center (and optionally standardize) a Polars DataFrame <code>target_col</code> partitioned by <code>over_col</code>.</p> <p>This returns a Polars expression, so it be chained in a <code>select</code> or <code>with_columns</code> invocation without needing to set a new intermediate DataFrame or materialize lazy evaluation.</p>"},{"location":"math/#torashii.math.center_xsection--parameters","title":"Parameters","text":"<p>target_col: the column to be standardized over_col: the column over which standardization should be applied, cross-sectionally standardize: boolean indicating if we should also standardize the target column</p>"},{"location":"math/#torashii.math.center_xsection--returns","title":"Returns","text":"<p>Polars Expr</p> Source code in <code>torashii/math.py</code> <pre><code>def center_xsection(target_col: str, over_col: str, standardize: bool = False) -&gt; pl.Expr:\n    \"\"\"Cross-sectionally center (and optionally standardize) a Polars DataFrame `target_col` partitioned by `over_col`.\n\n    This returns a Polars expression, so it be chained in a `select` or `with_columns` invocation\n    without needing to set a new intermediate DataFrame or materialize lazy evaluation.\n\n    Parameters\n    ----------\n    target_col: the column to be standardized\n    over_col: the column over which standardization should be applied, cross-sectionally\n    standardize: boolean indicating if we should also standardize the target column\n\n    Returns\n    -------\n    Polars Expr\n    \"\"\"\n    expr = pl.col(target_col) - pl.col(target_col).drop_nulls().drop_nans().mean().over(over_col)\n    if standardize:\n        return expr / pl.col(target_col).drop_nulls().drop_nans().std().over(over_col)\n    return expr\n</code></pre>"},{"location":"math/#torashii.math.exp_weights","title":"<code>exp_weights(window, half_life)</code>","text":"<p>Generate exponentially decaying weights over <code>window</code> trailing values, decaying by half each <code>half_life</code> index.</p>"},{"location":"math/#torashii.math.exp_weights--parameters","title":"Parameters","text":"<p>window: integer number of points in the trailing lookback period half_life: integer decay rate</p>"},{"location":"math/#torashii.math.exp_weights--returns","title":"Returns","text":"<p>numpy array</p> Source code in <code>torashii/math.py</code> <pre><code>def exp_weights(window: int, half_life: int) -&gt; np.ndarray:\n    \"\"\"Generate exponentially decaying weights over `window` trailing values, decaying by half each `half_life` index.\n\n    Parameters\n    ----------\n    window: integer number of points in the trailing lookback period\n    half_life: integer decay rate\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    try:\n        assert isinstance(window, int)\n        if not window &gt; 0:\n            raise ValueError(\"`window` must be a strictly positive integer\")\n    except (AttributeError, AssertionError) as e:\n        raise TypeError(\"`window` must be an integer type\") from e\n    try:\n        assert isinstance(half_life, int)\n        if not half_life &gt; 0:\n            raise ValueError(\"`half_life` must be a strictly positive integer\")\n    except (AttributeError, AssertionError) as e:\n        raise TypeError(\"`half_life` must be an integer type\") from e\n    decay = np.log(2) / half_life\n    return np.exp(-decay * np.arange(window))[::-1]\n</code></pre>"},{"location":"math/#torashii.math.norm_xsection","title":"<code>norm_xsection(target_col, over_col, lower=0, upper=1)</code>","text":"<p>Cross-sectionally normalize a Polars DataFrame <code>target_col</code> partitioned by <code>over_col</code>, with rescaling to the interval [<code>lower</code>, <code>upper</code>].</p> <p>This returns a Polars expression, so it can be chained in a <code>select</code> or <code>with_columns</code> invocation without needing to set a new intermediate DataFrame or materialize lazy evaluation.</p> <p>NaN values are not propagated in the max and min calculation, but NaN values are preserved for normalization.</p>"},{"location":"math/#torashii.math.norm_xsection--parameters","title":"Parameters","text":"<p>target_col: str name of the column to normalize over_col: str name of the column to partition the normalization by lower: lower bound of the rescaling interval, defaults to 0 to construct a percent upper: upper bound of the rescaling interval, defaults to 1 to construct a percent</p>"},{"location":"math/#torashii.math.norm_xsection--returns","title":"Returns","text":"<p>Polars Expr</p> Source code in <code>torashii/math.py</code> <pre><code>def norm_xsection(\n    target_col: str,\n    over_col: str,\n    lower: int | float = 0,\n    upper: int | float = 1,\n) -&gt; pl.Expr:\n    \"\"\"Cross-sectionally normalize a Polars DataFrame `target_col` partitioned by `over_col`, with rescaling\n    to the interval [`lower`, `upper`].\n\n    This returns a Polars expression, so it can be chained in a `select` or `with_columns` invocation\n    without needing to set a new intermediate DataFrame or materialize lazy evaluation.\n\n    NaN values are not propagated in the max and min calculation, but NaN values are preserved for normalization.\n\n    Parameters\n    ----------\n    target_col: str name of the column to normalize\n    over_col: str name of the column to partition the normalization by\n    lower: lower bound of the rescaling interval, defaults to 0 to construct a percent\n    upper: upper bound of the rescaling interval, defaults to 1 to construct a percent\n\n    Returns\n    -------\n    Polars Expr\n    \"\"\"\n    min_col = pl.col(target_col).drop_nans().min().over(over_col)\n    max_col = pl.col(target_col).drop_nans().max().over(over_col)\n\n    norm_col = (\n        pl.when(pl.col(target_col).is_nan())\n        .then(pl.col(target_col))  # Preserve NaN values\n        .when(max_col != min_col)  # Avoid division by zero by making sure min != max\n        .then((pl.col(target_col) - min_col) / (max_col - min_col) * (upper - lower) + lower)\n        .otherwise(lower)\n    )\n\n    return norm_col\n</code></pre>"},{"location":"math/#torashii.math.percentiles_xsection","title":"<code>percentiles_xsection(target_col, over_col, lower_pct, upper_pct, fill_val=0.0)</code>","text":"<p>Cross-sectionally mark all values of <code>target_col</code> that fall outside the <code>lower_pct</code> percentile or <code>upper_pct</code> percentile, within each <code>over_col</code> group. This is essentially an anti-winsorization, suitable for building high - low portfolios. The <code>fill_val</code> is inserted to each value between the percentile cutoffs.</p> <p>This returns a Polars expression, so it be chained in a <code>select</code> or <code>with_columns</code> invocation without needing to set a new intermediate DataFrame or materialize lazy evaluation.</p>"},{"location":"math/#torashii.math.percentiles_xsection--parameters","title":"Parameters","text":"<p>target_col: str column name to have non-percentile thresholded values masked over_col: str column name to apply masking over, cross-sectionally lower_pct: float lower percentile under which to keep values upper_pct: float upper percentile over which to keep values fill_val: numeric value for masking</p>"},{"location":"math/#torashii.math.percentiles_xsection--returns","title":"Returns","text":"<p>Polars Expr</p> Source code in <code>torashii/math.py</code> <pre><code>def percentiles_xsection(\n    target_col: str,\n    over_col: str,\n    lower_pct: float,\n    upper_pct: float,\n    fill_val: float | int = 0.0,\n) -&gt; pl.Expr:\n    \"\"\"Cross-sectionally mark all values of `target_col` that fall outside the `lower_pct` percentile or\n    `upper_pct` percentile, within each `over_col` group. This is essentially an anti-winsorization, suitable for\n    building high - low portfolios. The `fill_val` is inserted to each value between the percentile cutoffs.\n\n    This returns a Polars expression, so it be chained in a `select` or `with_columns` invocation\n    without needing to set a new intermediate DataFrame or materialize lazy evaluation.\n\n    Parameters\n    ----------\n    target_col: str column name to have non-percentile thresholded values masked\n    over_col: str column name to apply masking over, cross-sectionally\n    lower_pct: float lower percentile under which to keep values\n    upper_pct: float upper percentile over which to keep values\n    fill_val: numeric value for masking\n\n    Returns\n    -------\n    Polars Expr\n    \"\"\"\n    return (\n        pl.when(\n            (pl.col(target_col) &lt;= pl.col(target_col).drop_nans().quantile(lower_pct).over(over_col))\n            | (pl.col(target_col) &gt;= pl.col(target_col).drop_nans().quantile(upper_pct).over(over_col))\n        )\n        .then(pl.col(target_col))\n        .otherwise(fill_val)\n    )\n</code></pre>"},{"location":"math/#torashii.math.winsorize","title":"<code>winsorize(data, percentile=0.05, axis=0)</code>","text":"<p>Windorize each vector of a 2D numpy array to symmetric percentiles given by <code>percentile</code>.</p> <p>This returns a Polars expression, not a DataFrame, so it be chained (including lazily) in a <code>select</code> or <code>with_columns</code> invocation without needing to set a new intermediate DataFrame variable.</p>"},{"location":"math/#torashii.math.winsorize--parameters","title":"Parameters","text":"<p>data: numpy array containing original data to be winsorized percentile: float indicating the percentiles to apply winsorization at axis: int indicating which axis to apply winsorization over (i.e. orientation if <code>dara</code> is 2D)</p>"},{"location":"math/#torashii.math.winsorize--returns","title":"Returns","text":"<p>numpy array</p> Source code in <code>torashii/math.py</code> <pre><code>def winsorize(data: np.ndarray, percentile: float = 0.05, axis: int = 0) -&gt; np.ndarray:\n    \"\"\"Windorize each vector of a 2D numpy array to symmetric percentiles given by `percentile`.\n\n    This returns a Polars expression, not a DataFrame, so it be chained (including lazily) in\n    a `select` or `with_columns` invocation without needing to set a new intermediate DataFrame variable.\n\n    Parameters\n    ----------\n    data: numpy array containing original data to be winsorized\n    percentile: float indicating the percentiles to apply winsorization at\n    axis: int indicating which axis to apply winsorization over (i.e. orientation if `dara` is 2D)\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    try:\n        if not 0 &lt;= percentile &lt;= 1:\n            raise ValueError(\"`percentile` must be between 0 and 1\")\n    except AttributeError as e:\n        raise TypeError(\"`percentile` must be a numeric type, such as an int or float\") from e\n\n    fin_data = np.where(np.isfinite(data), data, np.nan)\n\n    # compute lower and upper percentiles for each column\n    lower_bounds = np.nanpercentile(fin_data, percentile * 100, axis=axis, keepdims=True)\n    upper_bounds = np.nanpercentile(fin_data, (1 - percentile) * 100, axis=axis, keepdims=True)\n\n    # clip data to within the bounds\n    return np.clip(data, lower_bounds, upper_bounds)\n</code></pre>"},{"location":"math/#torashii.math.winsorize_xsection","title":"<code>winsorize_xsection(df, data_cols, group_col, percentile=0.05)</code>","text":"<p>Cross-sectionally winsorize the <code>data_cols</code> of <code>df</code>, grouped on <code>group_col</code>, to the symmetric percentile given by <code>percentile</code>.</p>"},{"location":"math/#torashii.math.winsorize_xsection--parameters","title":"Parameters","text":"<p>df: Polars DataFrame or LazyFrame containing feature data to winsorize data_cols: collection of strings indicating the columns of <code>df</code> to be winsorized group_col: str column of <code>df</code> to use as the cross-sectional group percentile: float value indicating the symmetric winsorization threshold</p>"},{"location":"math/#torashii.math.winsorize_xsection--returns","title":"Returns","text":"<p>Polars DataFrame or LazyFrame</p> Source code in <code>torashii/math.py</code> <pre><code>def winsorize_xsection(\n    df: pl.DataFrame | pl.LazyFrame,\n    data_cols: tuple[str, ...],\n    group_col: str,\n    percentile: float = 0.05,\n) -&gt; pl.DataFrame | pl.LazyFrame:\n    \"\"\"Cross-sectionally winsorize the `data_cols` of `df`, grouped on `group_col`, to the symmetric percentile\n    given by `percentile`.\n\n    Parameters\n    ----------\n    df: Polars DataFrame or LazyFrame containing feature data to winsorize\n    data_cols: collection of strings indicating the columns of `df` to be winsorized\n    group_col: str column of `df` to use as the cross-sectional group\n    percentile: float value indicating the symmetric winsorization threshold\n\n    Returns\n    -------\n    Polars DataFrame or LazyFrame\n    \"\"\"\n\n    def winsorize_group(group: pl.DataFrame) -&gt; pl.DataFrame:\n        for col in data_cols:\n            winsorized_data = winsorize(group[col].to_numpy(), percentile=percentile)\n            group = group.with_columns(pl.Series(col, winsorized_data).alias(col))\n        return group\n\n    match df:\n        case pl.DataFrame():\n            grouped = df.group_by(group_col).map_groups(winsorize_group)\n        case pl.LazyFrame():\n            grouped = df.group_by(group_col).map_groups(winsorize_group, schema=df.collect_schema())\n        case _:\n            raise TypeError(\"`df` must be a Polars DataFrame or LazyFrame\")\n    return grouped\n</code></pre>"},{"location":"model/","title":"Torashii Model","text":"<p>Complete implementation of the factor model.</p>"},{"location":"model/#torashii.model.estimate_factor_returns","title":"<code>estimate_factor_returns(returns_df, mkt_cap_df, sector_df, style_df, winsor_factor=0.05, residualize_styles=True)</code>","text":"<p>Estimate factor and residual returns across all time periods using input asset factor scores.</p>"},{"location":"model/#torashii.model.estimate_factor_returns--parameters","title":"Parameters","text":"<p>returns_df: Polars DataFrame containing | date | symbol | asset_returns | mkt_cap_df: Polars DataFrame containing | date | symbol | market_cap | sector_df: Polars DataFrame containing | date | symbol | followed by one column for each sector style_df: Polars DataFrame containing | date | symbol | followed by one column for each style winsor_factor: winsorization proportion residualize_styles: bool indicating if style returns should be orthogonalized to market + sector returns</p>"},{"location":"model/#torashii.model.estimate_factor_returns--returns","title":"Returns","text":"<p>tuple of Polars DataFrames melted by date: (factor returns, residual returns)</p> Source code in <code>torashii/model.py</code> <pre><code>def estimate_factor_returns(\n    returns_df: pl.DataFrame,\n    mkt_cap_df: pl.DataFrame,\n    sector_df: pl.DataFrame,\n    style_df: pl.DataFrame,\n    winsor_factor: float | None = 0.05,\n    residualize_styles: bool = True,\n) -&gt; tuple[pl.DataFrame, pl.DataFrame] | pl.DataFrame:\n    \"\"\"Estimate factor and residual returns across all time periods using input asset factor scores.\n\n    Parameters\n    ----------\n    returns_df: Polars DataFrame containing | date | symbol | asset_returns |\n    mkt_cap_df: Polars DataFrame containing | date | symbol | market_cap |\n    sector_df: Polars DataFrame containing | date | symbol | followed by one column for each sector\n    style_df: Polars DataFrame containing | date | symbol | followed by one column for each style\n    winsor_factor: winsorization proportion\n    residualize_styles: bool indicating if style returns should be orthogonalized to market + sector returns\n\n    Returns\n    -------\n    tuple of Polars DataFrames melted by date: (factor returns, residual returns)\n    \"\"\"\n    returns, residuals = [], []\n    try:\n        sectors = sorted(sector_df.select(pl.exclude(\"date\", \"symbol\")).columns)\n    except AttributeError as e:\n        raise TypeError(\"`sector_df` must be a Polars DataFrame, but it's missing required attributes\") from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\"`sector_df` must have columns for 'date' and 'symbol' in addition to each sector\") from e\n    try:\n        styles = sorted(style_df.select(pl.exclude(\"date\", \"symbol\")).columns)\n    except AttributeError as e:\n        raise TypeError(\"`style_df` must be a Polars DataFrame, but it's missing required attributes\") from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\"`style_df` must have columns for 'date' and 'symbol' in addition to each style\") from e\n    try:\n        returns_df = (\n            returns_df.join(mkt_cap_df, on=[\"date\", \"symbol\"])\n            .join(sector_df, on=[\"date\", \"symbol\"])\n            .join(style_df, on=[\"date\", \"symbol\"])\n        )\n        dates = returns_df[\"date\"].unique().to_list()\n        # iterate through, one day at a time\n        # this could probably be made more efficient with Polars' `.map_groups` method\n        for dt in dates:\n            ddf = returns_df.filter(pl.col(\"date\") == dt).sort(\"symbol\")\n            r = ddf[\"asset_returns\"].to_numpy()\n            if winsor_factor is not None:\n                r = winsorize(r, winsor_factor)\n            f, e = _factor_returns(\n                r,\n                ddf[\"market_cap\"].to_numpy(),\n                ddf.select(sectors).to_numpy(),\n                ddf.select(styles).to_numpy(),\n                residualize_styles,\n            )\n            returns.append(f)\n            residuals.append(dict(zip(ddf[\"symbol\"].to_list(), e)))\n    except AttributeError as e:\n        raise TypeError(\n            \"`returns_df` and `mkt_cap_df` must be Polars DataFrames, but there are missing attributes\"\n        ) from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\n            \"`returns_df` must have columns 'date', 'symbol' and 'asset_returns'; \"\n            \"`mkt_cap_df` must have 'date', 'symbol' and 'market_cap' columns\"\n        ) from e\n    ret_df = pl.DataFrame(np.array(returns))\n    ret_df.columns = [\"market\"] + sectors + styles\n    ret_df = ret_df.with_columns(pl.Series(dates).alias(\"date\"))\n    eps_df = pl.DataFrame(residuals).with_columns(pl.Series(dates).alias(\"date\"))\n    return ret_df, eps_df\n</code></pre>"},{"location":"styles/","title":"Torashii Style Factors","text":"<p>Style factor implementations.</p>"},{"location":"styles/#torashii.styles.factor_mom","title":"<code>factor_mom(returns_df, trailing_days=504, half_life=126, lag=20, winsor_factor=0.01)</code>","text":"<p>Estimate rolling symbol by symbol momentum factor scores using asset returns.</p>"},{"location":"styles/#torashii.styles.factor_mom--parameters","title":"Parameters","text":"<p>returns_df: Polars DataFrame containing columns: | date | symbol | asset_returns | trailing_days: int look back period over which to measure momentum half_life: int decay rate for exponential weighting, in days lag: int number of days to lag the current day's return observation (20 trading days is one month)</p>"},{"location":"styles/#torashii.styles.factor_mom--returns","title":"Returns","text":"<p>Polars DataFrame containing columns: | date | symbol | mom_score |</p> Source code in <code>torashii/styles.py</code> <pre><code>def factor_mom(\n    returns_df: pl.DataFrame | pl.LazyFrame,\n    trailing_days: int = 504,\n    half_life: int = 126,\n    lag: int = 20,\n    winsor_factor: float = 0.01,\n) -&gt; pl.LazyFrame:\n    \"\"\"Estimate rolling symbol by symbol momentum factor scores using asset returns.\n\n    Parameters\n    ----------\n    returns_df: Polars DataFrame containing columns: | date | symbol | asset_returns |\n    trailing_days: int look back period over which to measure momentum\n    half_life: int decay rate for exponential weighting, in days\n    lag: int number of days to lag the current day's return observation (20 trading days is one month)\n\n    Returns\n    -------\n    Polars DataFrame containing columns: | date | symbol | mom_score |\n    \"\"\"\n    weights = exp_weights(trailing_days, half_life)\n\n    def weighted_cumprod(values: np.ndarray) -&gt; float:\n        return (np.cumprod(1 + (values * weights[-len(values) :])) - 1)[-1]  # type: ignore\n\n    try:\n        df = (\n            returns_df.lazy()\n            .sort(by=\"date\")\n            .with_columns(pl.col(\"asset_returns\").shift(lag).over(\"symbol\").alias(\"asset_returns\"))\n            .with_columns(\n                pl.col(\"asset_returns\")\n                .rolling_map(weighted_cumprod, window_size=trailing_days)\n                .over(pl.col(\"symbol\"))\n                .alias(\"mom_score\")\n            )\n        ).collect()\n        df = winsorize_xsection(df, (\"mom_score\",), \"date\", percentile=winsor_factor)\n        return df.lazy().select(\n            pl.col(\"date\"),\n            pl.col(\"symbol\"),\n            center_xsection(\"mom_score\", \"date\", True).alias(\"mom_score\"),\n        )\n    except AttributeError as e:\n        raise TypeError(\"`returns_df` must be a Polars DataFrame | LazyFrame, but it's missing attributes\") from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\"`returns_df` must have 'date', 'symbol' and 'asset_returns' columns\") from e\n</code></pre>"},{"location":"styles/#torashii.styles.factor_sze","title":"<code>factor_sze(mkt_cap_df, lower_decile=0.2, upper_decile=0.8)</code>","text":"<p>Estimate rolling symbol by symbol size factor scores using asset market caps.</p>"},{"location":"styles/#torashii.styles.factor_sze--parameters","title":"Parameters","text":"<p>mkt_cap_df: Polars DataFrame containing columns: | date | symbol | market_cap |</p>"},{"location":"styles/#torashii.styles.factor_sze--returns","title":"Returns","text":"<p>Polars DataFrame containing columns: | date | symbol | sze_score |</p> Source code in <code>torashii/styles.py</code> <pre><code>def factor_sze(\n    mkt_cap_df: pl.DataFrame | pl.LazyFrame,\n    lower_decile: float = 0.2,\n    upper_decile: float = 0.8,\n) -&gt; pl.LazyFrame:\n    \"\"\"Estimate rolling symbol by symbol size factor scores using asset market caps.\n\n    Parameters\n    ----------\n    mkt_cap_df: Polars DataFrame containing columns: | date | symbol | market_cap |\n\n    Returns\n    -------\n    Polars DataFrame containing columns: | date | symbol | sze_score |\n    \"\"\"\n    try:\n        return (\n            mkt_cap_df.lazy()\n            # our factor is the Fama-French SMB, i.e. small-minus-big, because the size risk premium\n            # is on the smaller firms rather than the larger ones. consequently we multiply by -1\n            .with_columns(pl.col(\"market_cap\").log().alias(\"sze_score\") * -1)\n            .with_columns(\n                \"date\",\n                \"symbol\",\n                (center_xsection(\"sze_score\", \"date\", True)).alias(\"sze_score\"),\n            )\n            .with_columns(percentiles_xsection(\"sze_score\", \"date\", lower_decile, upper_decile, 0.0).alias(\"sze_score\"))\n            .select(\"date\", \"symbol\", \"sze_score\")\n        )\n    except AttributeError as e:\n        raise TypeError(\"`mkt_cap_df` must be a Polars DataFrame or LazyFrame, but it's missing attributes\") from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\"`mkt_cap_df` must have 'date', 'symbol' and 'market_cap' columns\") from e\n</code></pre>"},{"location":"styles/#torashii.styles.factor_val","title":"<code>factor_val(value_df, winsorize_features=None)</code>","text":"<p>Estimate rolling symbol by symbol value factor scores using price ratios.</p>"},{"location":"styles/#torashii.styles.factor_val--parameters","title":"Parameters","text":"<p>value_df: Polars DataFrame containing columns: | date | symbol | book_price | sales_price | cf_price winsorize_features: optional float indicating if the features should be winsorized. none applied if None</p>"},{"location":"styles/#torashii.styles.factor_val--returns","title":"Returns","text":"<p>Polars DataFrame containing: | date | symbol | val_score |</p> Source code in <code>torashii/styles.py</code> <pre><code>def factor_val(value_df: pl.DataFrame | pl.LazyFrame, winsorize_features: float | None = None) -&gt; pl.LazyFrame:\n    \"\"\"Estimate rolling symbol by symbol value factor scores using price ratios.\n\n    Parameters\n    ----------\n    value_df: Polars DataFrame containing columns: | date | symbol | book_price | sales_price | cf_price\n    winsorize_features: optional float indicating if the features should be winsorized. none applied if None\n\n    Returns\n    -------\n    Polars DataFrame containing: | date | symbol | val_score |\n    \"\"\"\n    try:\n        if winsorize_features is not None:\n            value_df = winsorize_xsection(value_df, (\"book_price\", \"sales_price\", \"cf_price\"), \"date\")\n        return (\n            value_df.lazy()\n            .with_columns(\n                pl.col(\"book_price\").log().alias(\"book_price\"),\n                pl.col(\"sales_price\").log().alias(\"sales_price\"),\n            )\n            .with_columns(\n                center_xsection(\"book_price\", \"date\", True).alias(\"book_price\"),\n                center_xsection(\"sales_price\", \"date\", True).alias(\"sales_price\"),\n                center_xsection(\"cf_price\", \"date\", True).alias(\"cf_price\"),\n            )\n            .with_columns(\n                # NB: it's imperative you've properly handled NaNs prior to this point\n                pl.mean_horizontal(\n                    pl.col(\"book_price\"),\n                    pl.col(\"sales_price\"),\n                    pl.col(\"cf_price\"),\n                ).alias(\"val_score\")\n            )\n            .select(\n                pl.col(\"date\"),\n                pl.col(\"symbol\"),\n                center_xsection(\"val_score\", \"date\", True).alias(\"val_score\"),\n            )\n        )\n    except AttributeError as e:\n        raise TypeError(\"`value_df` must be a Polars DataFrame or LazyFrame, but it's missing attributes\") from e\n    except pl_exc.ColumnNotFoundError as e:\n        raise ValueError(\n            \"`value_df` must have 'date', 'symbol', 'book_price', 'sales_price' and 'fcf_price' columns\"\n        ) from e\n</code></pre>"},{"location":"utils/","title":"Torashii Utils","text":"<p>Utility functions, primarily for data cleaning.</p>"},{"location":"utils/#torashii.utils.fill_features","title":"<code>fill_features(df, features, sort_col, over_col)</code>","text":"<p>Cast feature columns to numeric (float), convert NaN and inf values to null, then forward fill nulls for each column of <code>features</code>, sorted on <code>sort_col</code> and partitioned by <code>over_col</code>.</p>"},{"location":"utils/#torashii.utils.fill_features--parameters","title":"Parameters","text":"<p>df: Polars DataFrame or LazyFrame containing columns <code>sort_col</code>, <code>over_col</code> and each of <code>features</code> features: collection of strings indicating which columns of <code>df</code> are the feature values sort_col: str column of <code>df</code> indicating how to sort over_col: str column of <code>df</code> indicating how to partition</p>"},{"location":"utils/#torashii.utils.fill_features--returns","title":"Returns","text":"<p>Polars LazyFrame containing the original columns with cleaned feature data</p> Source code in <code>torashii/utils.py</code> <pre><code>def fill_features(\n    df: pl.DataFrame | pl.LazyFrame, features: tuple[str, ...], sort_col: str, over_col: str\n) -&gt; pl.LazyFrame:\n    \"\"\"Cast feature columns to numeric (float), convert NaN and inf values to null, then forward fill nulls\n    for each column of `features`, sorted on `sort_col` and partitioned by `over_col`.\n\n    Parameters\n    ----------\n    df: Polars DataFrame or LazyFrame containing columns `sort_col`, `over_col` and each of `features`\n    features: collection of strings indicating which columns of `df` are the feature values\n    sort_col: str column of `df` indicating how to sort\n    over_col: str column of `df` indicating how to partition\n\n    Returns\n    -------\n    Polars LazyFrame containing the original columns with cleaned feature data\n    \"\"\"\n    try:\n        # eagerly check all `features`, `sort_col`, `over_col` present: can't catch ColumNotFoundError in lazy context\n        assert all(c in df.columns for c in features + (sort_col, over_col))\n        return (\n            df.lazy()\n            .with_columns([pl.col(f).cast(float).alias(f) for f in features])\n            .with_columns(\n                [\n                    pl.when(\n                        (pl.col(f).abs() == np.inf)\n                        | (pl.col(f) == np.nan)\n                        | (pl.col(f).is_null())\n                        | (pl.col(f).cast(str) == \"NaN\")\n                    )\n                    .then(None)\n                    .otherwise(pl.col(f))\n                    .alias(f)\n                    for f in features\n                ]\n            )\n            .sort(by=sort_col)\n            .with_columns([pl.col(f).forward_fill().over(over_col).alias(f) for f in features])\n        )\n    except AttributeError as e:\n        raise TypeError(\"`df` must be a Polars DataFrame | LazyFrame, but it's missing required attributes\") from e\n    except AssertionError as e:\n        raise ValueError(f\"`df` must have all of {[over_col, sort_col] + list(features)} as columns\") from e\n</code></pre>"},{"location":"utils/#torashii.utils.smooth_features","title":"<code>smooth_features(df, features, sort_col, over_col, window_size)</code>","text":"<p>Smooth the <code>features</code> columns of <code>df</code> by taking the rolling mean of each, sorted over <code>sort_col</code> and partitioned by <code>over_col</code>, using <code>window_size</code> trailing periods for the moving average window.</p>"},{"location":"utils/#torashii.utils.smooth_features--parameters","title":"Parameters","text":"<p>df: Polars DataFrame | LazyFrame containing columns <code>sort_col</code>, <code>over_col</code> and each of <code>features</code> features: collection of strings indicating which columns of <code>df</code> are the feature values sort_col: str column of <code>df</code> indicating how to sort over_col: str column of <code>df</code> indicating how to partition window_size: int number of time periods for the moving average</p>"},{"location":"utils/#torashii.utils.smooth_features--returns","title":"Returns","text":"<p>Polars LazyFrame containing the original columns, with each of <code>features</code> replaced with moving average</p> Source code in <code>torashii/utils.py</code> <pre><code>def smooth_features(\n    df: pl.DataFrame | pl.LazyFrame,\n    features: tuple[str, ...],\n    sort_col: str,\n    over_col: str,\n    window_size: int,\n) -&gt; pl.LazyFrame:\n    \"\"\"Smooth the `features` columns of `df` by taking the rolling mean of each, sorted over `sort_col` and\n    partitioned by `over_col`, using `window_size` trailing periods for the moving average window.\n\n    Parameters\n    ----------\n    df: Polars DataFrame | LazyFrame containing columns `sort_col`, `over_col` and each of `features`\n    features: collection of strings indicating which columns of `df` are the feature values\n    sort_col: str column of `df` indicating how to sort\n    over_col: str column of `df` indicating how to partition\n    window_size: int number of time periods for the moving average\n\n    Returns\n    -------\n    Polars LazyFrame containing the original columns, with each of `features` replaced with moving average\n    \"\"\"\n    try:\n        # eagerly check `over_col`, `sort_col`, `features` present: can't catch pl.ColumnNotFoundError in lazy context\n        assert all(c in df.columns for c in features + (over_col, sort_col))\n        return (\n            df.lazy()\n            .sort(by=sort_col)\n            .with_columns([pl.col(f).rolling_mean(window_size=window_size).over(over_col).alias(f) for f in features])\n        )\n    except AttributeError as e:\n        raise TypeError(\"`df` must be a Polars DataFrame | LazyFrame, but it's missing required attributes\") from e\n    except AssertionError as e:\n        raise ValueError(f\"`df` must have all of {[over_col, sort_col] + list(features)} as columns\") from e\n</code></pre>"},{"location":"utils/#torashii.utils.top_n_by_group","title":"<code>top_n_by_group(df, n, rank_var, group_var, filter=True)</code>","text":"<p>Mark the top <code>n</code> rows in each of <code>group_var</code> according to <code>rank_var</code> descending.</p> <p>If <code>filter</code> is True, the returned DataFrame contains only the filtered data. If <code>filter</code> is False, the returned DataFrame has all data, with an additional 'rank_mask' column indicating if that row is in the filter.</p>"},{"location":"utils/#torashii.utils.top_n_by_group--parameters","title":"Parameters","text":"<p>df: Polars DataFrame | LazyFrame n: integer indicating the top rows to take in each group rank_var: str column name to rank on group_var: tuple of str column names to group and sort on filter: boolean indicating how much data to return</p>"},{"location":"utils/#torashii.utils.top_n_by_group--returns","title":"Returns","text":"<p>Polars LazyFrame containing original columns and optional filter column</p> Source code in <code>torashii/utils.py</code> <pre><code>def top_n_by_group(\n    df: pl.DataFrame | pl.LazyFrame,\n    n: int,\n    rank_var: str,\n    group_var: tuple[str, ...],\n    filter: bool = True,\n) -&gt; pl.LazyFrame:\n    \"\"\"Mark the top `n` rows in each of `group_var` according to `rank_var` descending.\n\n    If `filter` is True, the returned DataFrame contains only the filtered data. If `filter` is False,\n    the returned DataFrame has all data, with an additional 'rank_mask' column indicating if that row\n    is in the filter.\n\n    Parameters\n    ----------\n    df: Polars DataFrame | LazyFrame\n    n: integer indicating the top rows to take in each group\n    rank_var: str column name to rank on\n    group_var: tuple of str column names to group and sort on\n    filter: boolean indicating how much data to return\n\n    Returns\n    -------\n    Polars LazyFrame containing original columns and optional filter column\n    \"\"\"\n    try:\n        # eagerly check `rank_var`, `group_var` are present: we can't catch a ColumnNotFoundError in a lazy context\n        assert all(c in df.columns for c in (rank_var,) + group_var)\n        rdf = (\n            df.lazy()\n            .sort(by=list(group_var) + [rank_var])\n            .with_columns(pl.col(rank_var).rank(descending=True).over(group_var).cast(int).alias(\"rank\"))\n        )\n        match filter:\n            case True:\n                return rdf.filter(pl.col(\"rank\") &lt;= n).drop(\"rank\").sort(by=list(group_var) + [rank_var])\n            case False:\n                return (\n                    rdf.with_columns(\n                        pl.when(pl.col(\"rank\") &lt;= n).then(pl.lit(1)).otherwise(pl.lit(0)).alias(\"rank_mask\")\n                    )\n                    .drop(\"rank\")\n                    .sort(by=list(group_var) + [rank_var])\n                )\n    except AssertionError as e:\n        raise ValueError(f\"`df` is missing one or more required columns: '{rank_var}' and '{group_var}'\") from e\n    except AttributeError as e:\n        raise TypeError(\"`df` must be a Polars DataFrame or LazyFrame but is missing a required attribute\") from e\n</code></pre>"}]}